{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4d6823138e10362d49fd34444a1010ea",
     "grade": false,
     "grade_id": "cell-5b46313c3ddaa966",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Assignment 3\n",
    "\n",
    "Welcome to the third assignment! Here you will implement a simple Content-Based Recommender. We will use part of the MovieLens 20M dataset.\n",
    "\n",
    "You will write and execute your code in Python using this Jupyter Notebook.\n",
    "\n",
    "**TASK:** Your job is to **fill in the missing code only** (!!!). The place to enter your code is clearly marked with comments.\n",
    "\n",
    "**SUBMISSION:** You will submit this Notebook via the Interface of JupyterHub.\n",
    "\n",
    "- Submissions are possible until **25.04.2023 23:59 CEST**.\n",
    "- Do **NOT** rename the file it needs to be named as \"assignment3.ipynb\" (in the case if you want to run the Jupyter Notebook offline).\n",
    "- Please **save** (\"File -> \"Save and Checkpoint\") and **close** your Jupyter Notebook (\"file\" -> \"Close and Halt\") before you hand in your solution.\n",
    "- Before handing in [check if your Jupyter Notebook **validates**]! \n",
    "- Please use the CLI to validate your solution. The button in the webinterface is not working if the JupyterNotebook runs more than just some seconds.\n",
    "\n",
    "**GRADING:** We will test whether your code produces the expected output. Therefore hidden tests will compare results of the standard solution with yours (based on the whole dataset - multiple, randomly selected inputs - accuracy of the solution must be within two decimal places). Note that the visible test cells are only an indicator for the correctness of your solution. They **do not** guarantee that your solution is correct. \n",
    "\n",
    "**Late submissions are not possible. We will automatically collect all submissions at the end of the deadline!**\n",
    "\n",
    "We reserve the right to carry out automatic plagiarism checks. Please do not exploit the submission system. We will look at all submissions and such submissions will be scored 0 points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d1c7946a38e271b460cc1cbfce394f1d",
     "grade": false,
     "grade_id": "cell-d7bd70547996f28c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Preparation\n",
    "Importing necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "658ae20af45f2e5e2dbb46760ee7b35b",
     "grade": false,
     "grade_id": "cell-14151cdb2a0cad2a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse as sp\n",
    "import sklearn.preprocessing as pp\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "#if you wish to disable warnings, uncomment the following two lines\n",
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "66939785ad1d25c36b80e5f3f9b54a53",
     "grade": false,
     "grade_id": "cell-45fb8d1e6d02f334",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=500, precision=4)\n",
    "pd.options.display.max_seq_items = 100\n",
    "%precision 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "363622de52d6dfefaa635c1102fb5ca4",
     "grade": false,
     "grade_id": "cell-8ac40463e009e648",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Make sure to enter the correct location of your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "revert": "data_directory = '~/shared/data/assignment3/'"
   },
   "outputs": [],
   "source": [
    "data_directory = '~/shared/data/assignment3/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cd6fef366e23b50207007846d95d3c0b",
     "grade": true,
     "grade_id": "load-data-for-grading",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e24b1da5c53a19650132dd92492e3811",
     "grade": false,
     "grade_id": "cell-832e4e82841c58cd",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Create the movies DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5f6108e04c7da9ac46d917ecccab1e46",
     "grade": false,
     "grade_id": "cell-14a129266cc43570",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "links = pd.read_csv(data_directory + 'links.csv')\n",
    "movies_plain = pd.read_csv(data_directory + 'movies.csv')\n",
    "metadata = pd.read_csv(data_directory + 'movies_metadata.csv', low_memory=False)\n",
    "metadata.drop(metadata.columns[[0,1,2,4,6,7,8,10,11,12,13,14,15,16,17,18,19,20,21,22,23]], axis=1, inplace=True)\n",
    "keywords = pd.read_csv(data_directory + 'keywords.csv', low_memory=False)\n",
    "credits = pd.read_csv(data_directory + 'credits.csv', low_memory=False)\n",
    "\n",
    "keywords['id'] = keywords['id'].astype('int')\n",
    "links=links[links['tmdbId'].isnull()==False]\n",
    "links['tmdbId'] = links['tmdbId'].astype('int')\n",
    "metadata = metadata.drop([19730, 29503, 35587])\n",
    "metadata['id'] = metadata['id'].astype('int')\n",
    "credits['id'] = credits['id'].astype('int')\n",
    "\n",
    "movies = metadata.merge(links, how='inner', left_on='id', right_on='tmdbId')\n",
    "movies = movies.merge(movies_plain, how='inner', left_on='movieId', right_on='movieId')\n",
    "movies = movies.merge(keywords, how='inner', left_on='id', right_on='id')\n",
    "movies = movies.merge(credits, how='inner', left_on='id', right_on='id')\n",
    "movies = movies.drop(columns=['tmdbId','genres_y'])\n",
    "movies.rename(columns={'genres_x': 'genres'}, inplace=True)\n",
    "\n",
    "movies=movies[movies['overview'].isnull()==False]\n",
    "\n",
    "movies = movies[movies['movieId'] < 1000]\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "features = ['cast', 'crew', 'keywords', 'genres']\n",
    "for feature in features:\n",
    "    movies[feature] = movies[feature].apply(literal_eval)\n",
    "    \n",
    "\n",
    "# Get the director's name from the crew feature. If director is not listed, return NaN\n",
    "def get_director(x):\n",
    "    for i in x:\n",
    "        if i['job'] == 'Director':\n",
    "            return i['name']\n",
    "    return np.nan\n",
    "\n",
    "# Returns the list top 3 elements or entire list; whichever is more.\n",
    "def get_list(x):\n",
    "    if isinstance(x, list):\n",
    "        names = [i['name'] for i in x]\n",
    "        #Check if more than 3 elements exist. If yes, return only first three. If no, return entire list.\n",
    "        if len(names) > 3:\n",
    "            names = names[:3]\n",
    "        return names\n",
    "\n",
    "    #Return empty list in case of missing/malformed data\n",
    "    return []\n",
    "\n",
    "# Define new director, cast, genres and keywords features that are in a suitable form.\n",
    "movies['director'] = movies['crew'].apply(get_director)\n",
    "\n",
    "features = ['cast', 'keywords', 'genres']\n",
    "for feature in features:\n",
    "    movies[feature] = movies[feature].apply(get_list)\n",
    "\n",
    "    \n",
    "# Function to convert all strings to lower case and strip names of spaces\n",
    "def clean_data(x):\n",
    "    if isinstance(x, list):\n",
    "        return [str.lower(i.replace(\" \", \"\")) for i in x]\n",
    "    else:\n",
    "        # Check if string exists. If not, return empty string\n",
    "        if isinstance(x, str):\n",
    "            return str.lower(x.replace(\" \", \"\"))\n",
    "        else:\n",
    "            return ''\n",
    "\n",
    "# Apply clean_data function to your features.\n",
    "features = ['cast', 'keywords', 'director', 'genres']\n",
    "\n",
    "for feature in features:\n",
    "    movies[feature] = movies[feature].apply(clean_data)\n",
    "\n",
    "    \n",
    "# Drop duplicate movies   \n",
    "import collections\n",
    "movie_ids = movies['movieId'].tolist()\n",
    "movie_ids_dup = [x for  x, y in collections.Counter(movie_ids).items() if y > 1]\n",
    "\n",
    "for movie_id in movie_ids_dup:\n",
    "    to_drop = movies.index[movies.movieId == movie_id].tolist()[1:]\n",
    "    movies.drop(to_drop, inplace=True)\n",
    "\n",
    "movies.drop(columns='crew', inplace=True)\n",
    "\n",
    "\n",
    "movies.rename(columns={'overview':'plot'}, inplace=True)\n",
    "\n",
    "def create_metadata(x):\n",
    "        return ' '.join(x['keywords']) + ' ' + ' '.join(x['cast']) + ' ' + x['director'] + ' ' + ' '.join(x['genres'])  \n",
    "\n",
    "# Create a new metadata feature\n",
    "movies['metadata'] = movies.apply(create_metadata, axis=1)\n",
    "\n",
    "display(movies.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "39919defb484ff03bb5e8e87f8cb2969",
     "grade": false,
     "grade_id": "cell-41a980612e2d0ae2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Create the ratings DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6d0245d274d3ad874460c5d7838e1fc3",
     "grade": false,
     "grade_id": "cell-6b990cb516f33d73",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "ratings = pd.read_csv(data_directory + 'ratings.csv')\n",
    "ratings = ratings.drop(columns=['timestamp'])\n",
    "ratings = ratings[(ratings['userId'] < 1000) & (ratings['movieId'] < 100) ]\n",
    "\n",
    "ratings = ratings[ratings['movieId'].isin(movies['movieId'])]\n",
    "\n",
    "## keep users with more than 2 ratings\n",
    "ratings_count = ratings.groupby(['userId', 'movieId']).size().groupby('userId').size()\n",
    "ratings_ok = ratings_count[ratings_count >= 2].reset_index()[['userId']]\n",
    "ratings = ratings.merge(ratings_ok, \n",
    "               how = 'right',\n",
    "               left_on = 'userId',\n",
    "               right_on = 'userId')\n",
    "\n",
    "\n",
    "ratings.columns = ['user', 'item', 'rating']\n",
    "\n",
    "item_ids = ratings['item'].unique()\n",
    "item_ids.sort()\n",
    "\n",
    "display(ratings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d743a1ad40656785b24d410262cc0feb",
     "grade": false,
     "grade_id": "cell-7c297f1005cdfaee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## trim movies dataframe to contain only movies in item_ids\n",
    "\n",
    "movies[movies['movieId'].isin(item_ids)] # TODO change to movies = movie[...], further change expected output below\n",
    "\n",
    "movies.rename(columns={'movieId': 'item_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "58f6b09cc849ae02912fea64168dc596",
     "grade": false,
     "grade_id": "cell-42c644e3fc158ff3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## The `Recommender_CB` class\n",
    "\n",
    "In the following, we will build functionality into the `Recommender_CB` class. The initialization stores the various data sources. A helper function returns the titles of movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aacd61f0c86a78dd316acbf375a1ae92",
     "grade": false,
     "grade_id": "cell-c6ed85a9f17210d4",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "class Recommender_CB:\n",
    "    \n",
    "    def __init__(self, profile_type='plot'):\n",
    "        self.profile_type = profile_type\n",
    "    \n",
    "    def build_model(self, ratings, items_meta):\n",
    "        self.ratings = ratings\n",
    "        self.items_meta = items_meta\n",
    "        \n",
    "        ## user_id and item_id are external ids; i_id is internal id\n",
    "        self.item_ids = self.ratings.item.unique()\n",
    "        self.item_ids.sort()\n",
    "        \n",
    "        self.user_ids = self.ratings.user.unique()\n",
    "        self.user_ids.sort()\n",
    "        \n",
    "        self.i_id_to_item_id = self.items_meta['item_id'].tolist()\n",
    "    \n",
    "    \n",
    "    def get_item_titles(self, item_ids):\n",
    "        return [ self.items_meta[self.items_meta['item_id'] == id]['title'].item() for id in item_ids] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f9575bae7ea817788f1740bcea4c07c1",
     "grade": false,
     "grade_id": "cell-d7f210fa140c0019",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Build the content of Items --- TO EDIT\n",
    "\n",
    "\n",
    "For the purpose of this assignment we consider two types of content.\n",
    "\n",
    "The first one, called *plot* content, is based on the movie's plot description, contained in attribute plot. \n",
    "\n",
    "The second one, called *meta* content, is based on the director, the actors, genres, and keywords for the movies, which are combined in the attribute metadata.\n",
    "\n",
    "We will build TF-IDF vectors for the movies based on the two types of contents. For this purpose, we will use the `TfIdfVectorizer` module from `scikit-learn`.\n",
    "\n",
    "Steps to implement:\n",
    "\n",
    "1. Apply the `vectorizer` on the `plot` column of `self.items_meta` to retrieve tf-idf vector for each movie. Store the result into `self.plot_tfidf`\n",
    "2. Get the feature names from the `vectorizer` and store them in `self.plot_tfidf_tokens`.\n",
    "3. Apply the `vectorizer` on the `metadata` column of `self.items_meta` to retrieve tf-idf vector for each movie. Store the result into `self.meta_tfidf`\n",
    "4. Get the feature names from the `vectorizer` and store them in `self.meta_tfidf_tokens`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ee3df4ef068254effac71787647262f7",
     "grade": false,
     "grade_id": "build-item-contents-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "revert": "def build_item_contents(self):\n    \"\"\"\n    This function creates a TF-IDF vector representation of the plot and the meta content.\n    \n    :var plot_tfidf: Tf-idf-weighted document-term matrix (shape: (n_items, n_features))\n    :type plot_tfidf: scipy.sparse.csr.csr_matrix\n    :var plot_tfidf_tokens: list of feature names\n    :type plot_tfidf_tokens: list\n    :var meta_tfidf: Tf-idf-weighted document-term matrix (shape: (n_items, n_features))\n    :type meta_tfidf: scipy.sparse.csr.csr_matrix\n    :var meta_tfidf_tokens: list of feature names\n    :type meta_tfidf_tokens: list\n\n\n    \n    \"\"\"\n    vectorizer = TfidfVectorizer(stop_words='english') # Define a TF-IDF Vectorizer that removes all english stop words (e.g., 'the', 'a')\n    \n    # YOUR CODE HERE\n    raise NotImplementedError()\n    \n    self.plot_tfidf.sort_indices()\n    self.meta_tfidf.sort_indices()\n    \n    self.set_content_type()\n\ndef set_content_type(self, profile_type='plot'):\n    if profile_type == 'plot':\n        self.tfidf = self.plot_tfidf\n        self.tfidf_tokens = self.plot_tfidf_tokens\n    else:\n        self.tfidf = self.meta_tfidf\n        self.tfidf_tokens = self.meta_tfidf_tokens"
   },
   "outputs": [],
   "source": [
    "def build_item_contents(self):\n",
    "    \"\"\"\n",
    "    This function creates a TF-IDF vector representation of the plot and the meta content.\n",
    "    \n",
    "    :var plot_tfidf: Tf-idf-weighted document-term matrix (shape: (n_items, n_features))\n",
    "    :type plot_tfidf: scipy.sparse.csr.csr_matrix\n",
    "    :var plot_tfidf_tokens: list of feature names\n",
    "    :type plot_tfidf_tokens: list\n",
    "    :var meta_tfidf: Tf-idf-weighted document-term matrix (shape: (n_items, n_features))\n",
    "    :type meta_tfidf: scipy.sparse.csr.csr_matrix\n",
    "    :var meta_tfidf_tokens: list of feature names\n",
    "    :type meta_tfidf_tokens: list\n",
    "\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    vectorizer = TfidfVectorizer(stop_words='english') # Define a TF-IDF Vectorizer that removes all english stop words (e.g., 'the', 'a')\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    arr = self.items_meta\n",
    "    arr = vectorizer.fit_transform(arr[\"plot\"])\n",
    "    arr2 = pd.DataFrame(arr.toarray().transpose(),index=vectorizer.get_feature_names_out())\n",
    "    self.plot_tfidf = arr\n",
    "    self.plot_tfidf_tokens = vectorizer.get_feature_names_out(arr2) \n",
    "    \n",
    "\n",
    "    arr = self.items_meta\n",
    "    arr = vectorizer.fit_transform(arr[\"metadata\"])\n",
    "    self.meta_tfidf = arr\n",
    "    arr2 = pd.DataFrame(arr.toarray().transpose(),index=vectorizer.get_feature_names_out())\n",
    "    self.meta_tfidf_tokens = vectorizer.get_feature_names_out(arr2)\n",
    "    \n",
    "    self.plot_tfidf.sort_indices()\n",
    "    self.meta_tfidf.sort_indices()\n",
    "    \n",
    "    self.set_content_type()\n",
    "\n",
    "def set_content_type(self, profile_type='plot'):\n",
    "    if profile_type == 'plot':\n",
    "        self.tfidf = self.plot_tfidf\n",
    "        self.tfidf_tokens = self.plot_tfidf_tokens\n",
    "    else:\n",
    "        self.tfidf = self.meta_tfidf\n",
    "        self.tfidf_tokens = self.meta_tfidf_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2a4fc150cb2a4cd97925b96ce471be20",
     "grade": false,
     "grade_id": "cell-d4538291958caf8a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Add the functions to the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bcc9b2fa85a8a78bece5a822016b36a3",
     "grade": false,
     "grade_id": "cell-0ec1c70ded425382",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "Recommender_CB.build_item_contents = build_item_contents\n",
    "Recommender_CB.set_content_type = set_content_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0a6067c9cc3d169450819d15ad246f3b",
     "grade": false,
     "grade_id": "cell-c9d9cecdcd69c2bc",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Test the function. (Shows only the nonzero vector coordinates.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "98e90536c59b36e80eb6529d836b1768",
     "grade": false,
     "grade_id": "cell-d6fcd5d7bf1476a9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "cbr = Recommender_CB()\n",
    "cbr.build_model(ratings, movies)\n",
    "\n",
    "cbr.build_item_contents()\n",
    "\n",
    "print(cbr.plot_tfidf.shape)\n",
    "print(cbr.plot_tfidf.data)\n",
    "# print(cbr.plot_tfidf)\n",
    "\n",
    "print(cbr.meta_tfidf.shape)\n",
    "print(cbr.meta_tfidf.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5bf82b275c2334ea9ad77b35ca2b580f",
     "grade": false,
     "grade_id": "cell-402176e452903fff",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**EXPECTED OUTPUT:**\n",
    "\n",
    "```\n",
    "(958, 9241)\n",
    "[0.1611 0.3988 0.1611 ... 0.124  0.0878 0.1253]\n",
    "(958, 3792)\n",
    "[0.2485 0.3649 0.1075 ... 0.2854 0.3717 0.4114]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1683e777913075103c2cfbffe0972bcb",
     "grade": true,
     "grade_id": "build-item-contents-tests",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c6aa3e3feb8c9b9fa7c4a5adb2fe488c",
     "grade": false,
     "grade_id": "cell-55837395e361105b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "The following function returns the vector representations for specified items. Vectors are stacked vertically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "44d5c433f81d06191c14e3bbfde99579",
     "grade": false,
     "grade_id": "cell-b8e56daa80e51055",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def get_item_vectors(self, item_ids):\n",
    "    i_ids = [self.i_id_to_item_id.index(item_id) for item_id in item_ids]\n",
    "    item_vector = self.tfidf[i_ids]\n",
    "    return item_vector "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f29a0e1594e64476b9715bf5f0c68618",
     "grade": false,
     "grade_id": "cell-3ee84e325aa42d7f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Add the function to the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f53d82b3b56614d5a7c69851d25f1d26",
     "grade": false,
     "grade_id": "cell-6f00b9e372bc281a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "Recommender_CB.get_item_vectors = get_item_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ab69bdc4ee7f0965a189b04aaedbc74b",
     "grade": false,
     "grade_id": "cell-57f34ea6ac0e1264",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Build the profiles of Users --- TO EDIT\n",
    "\n",
    "The following function computes the user profile as a vector that averages the tf-idf vectors of all items the user has rated, weighted by the ratings of the user. \n",
    "\n",
    "Steps to implement:\n",
    "\n",
    "1. Get the td-idf vectors corresponding to the items rated by the user.\n",
    "2. Compute a weighted average of these vectors, where each vector is weighted by the rating of the user to it. Store the output into the `user_profile` vector. Tips: You may want to use `scipy.sparse.csr_matrix.multiply` to multiply the sparse td-idf vectors with the user ratings. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0158646110f6030c8192f7746f5be2e0",
     "grade": false,
     "grade_id": "get-user-profile-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "revert": "def get_user_profile(self, user_id, ratings):\n    \"\"\"\n    This function takes a user ID and a ratings array  as input.\n    \n    :return: user profile as array of weighted average of tf-idf vectors corresponding to\n             the items rated by the user (1, self.tfidf.shape[1])\n    :rtype: numpy.ndarray\n    \"\"\"\n    \n    item_ids_rated_by_user_id = np.array( ratings.loc[ ratings['user'] == user_id ]['item'] )\n    user_ratings = np.array( ratings.loc[ ratings['user'] == user_id ]['rating'] )\n\n    # YOUR CODE HERE\n    raise NotImplementedError()\n\n    user_profile = pp.normalize(user_profile)\n    print(user_profile.shape)\n    print(type(user_profile))\n\n    return user_profile"
   },
   "outputs": [],
   "source": [
    "def get_user_profile(self, user_id, ratings):\n",
    "    \"\"\"\n",
    "    This function takes a user ID and a ratings array  as input.\n",
    "    \n",
    "    :return: user profile as array of weighted average of tf-idf vectors corresponding to\n",
    "             the items rated by the user (1, self.tfidf.shape[1])\n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\"\n",
    "    \n",
    "    item_ids_rated_by_user_id = np.array( ratings.loc[ ratings['user'] == user_id ]['item'] )\n",
    "    user_ratings = np.array( ratings.loc[ ratings['user'] == user_id ]['rating'] )\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    arr = get_item_vectors(self, item_ids_rated_by_user_id)\n",
    "    arr = arr.multiply(user_ratings[:, np.newaxis])\n",
    "    arr = arr.toarray().transpose()\n",
    "    newlist = []\n",
    "    for i in range(len(arr)):\n",
    "        newlist.append(sum(arr[i])/len(user_ratings))\n",
    "    user_profile = np.array([newlist])\n",
    "\n",
    "    user_profile = pp.normalize(user_profile)\n",
    "    #print(user_profile.shape)\n",
    "    #print(type(user_profile))\n",
    "\n",
    "    return user_profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c8a2feb6243f143306c47240af609a36",
     "grade": false,
     "grade_id": "cell-66e54803106968de",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Add the function to the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8a5f77dd2293fd7d710f25242486e996",
     "grade": false,
     "grade_id": "cell-771ffff1628f5495",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "Recommender_CB.get_user_profile = get_user_profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ea69902f55eb0c22d44c6da2594a50e2",
     "grade": false,
     "grade_id": "cell-ee1b04b18fe6073e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Test the function. (Shows only the nonzero vector coordinates.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4a34a9a5de42e2f82533dc66841c7506",
     "grade": false,
     "grade_id": "cell-7352cb3099539f29",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "user_profile = cbr.get_user_profile(1, ratings)\n",
    "print(user_profile[user_profile.nonzero()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1504bcce58a1f830fcaea0d0df70a822",
     "grade": false,
     "grade_id": "cell-f0fbce625ba32564",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**EXPECTED OUTPUT:**\n",
    "\n",
    "```\n",
    "[0.052  0.0574 0.0574 0.0658 0.0789 0.0789 0.144  0.1336 0.0501 0.0557\n",
    " 0.0538 0.0546 0.0668 0.0596 0.1071 0.1241 0.0658 0.0574 0.066  0.0713\n",
    " 0.0957 0.0741 0.0619 0.1084 0.0638 0.0768 0.0741 0.1027 0.0594 0.0757\n",
    " 0.0612 0.0493 0.0714 0.1132 0.0467 0.0741 0.0741 0.0713 0.066  0.0511\n",
    " 0.0757 0.052  0.066  0.0442 0.0714 0.041  0.0713 0.0434 0.0651 0.1775\n",
    " 0.0688 0.0658 0.0398 0.0714 0.0741 0.0611 0.0587 0.0557 0.0768 0.0601\n",
    " 0.1286 0.0543 0.0741 0.066  0.1388 0.0501 0.0757 0.0757 0.0789 0.051\n",
    " 0.0658 0.0744 0.0658 0.0574 0.0757 0.139  0.1555 0.0757 0.0641 0.0499\n",
    " 0.0594 0.1174 0.0757 0.0636 0.0379 0.051  0.0587 0.085  0.0741 0.0557\n",
    " 0.1365 0.0684 0.0413 0.0757 0.0531 0.085  0.0688 0.0658 0.0611 0.0684\n",
    " 0.0658 0.0684 0.0583 0.0621 0.1316 0.0668 0.0714 0.0543 0.0658 0.0557\n",
    " 0.072  0.085  0.1168 0.0789 0.0744 0.0594 0.1142 0.0612 0.0587 0.1196\n",
    " 0.085  0.0802 0.0893 0.0659 0.0686 0.0744 0.085  0.085  0.144  0.1178\n",
    " 0.085  0.0363 0.0757 0.1236 0.0361 0.066  0.1594 0.1278 0.0459 0.0789\n",
    " 0.0574 0.0344 0.0802 0.0688 0.0531 0.0658 0.0768 0.0688 0.1514 0.0686\n",
    " 0.0768 0.1188 0.0621 0.0594 0.0395 0.0349 0.0408]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1a789c22737fe8cad72c19b488bca09e",
     "grade": true,
     "grade_id": "get-user-profile-test",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d7cfdc5ea2d7db32b3024a2eb7833c84",
     "grade": false,
     "grade_id": "cell-258bb414dfd7336b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Build the profiles of all users. Use only the positive rankings (positive feedback) to determine weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "013fa378db9004552d16f4671b1aa155",
     "grade": false,
     "grade_id": "cell-1025ef640bfc2a09",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def build_user_profiles(self):\n",
    "    positive_ratings = self.ratings[ratings.rating>3]\n",
    "    self.user_profiles = {}\n",
    "    for user_id in positive_ratings['user'].unique():\n",
    "        self.user_profiles[user_id] = self.get_user_profile(user_id, positive_ratings)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e4781f8cb57d2e2ba705332bb446ed36",
     "grade": false,
     "grade_id": "cell-23362adab2b7e282",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "Recommender_CB.build_user_profiles = build_user_profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b805631a4532c3111cd2e7cb36530ca1",
     "grade": false,
     "grade_id": "cell-05c058e734542d79",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cbr.build_user_profiles()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b5c22550c76ccaeaacb094b8f37c1a5d",
     "grade": false,
     "grade_id": "cell-c9fe4b3cebb541c6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Make Recommendations --- TO EDIT\n",
    "\n",
    "\n",
    "The following function recommends topN items to the user based on her/his profile. The recommendations should exclude items already rated by the user.\n",
    "\n",
    "Steps to implement:\n",
    "\n",
    "1. Retrieve the user profile.\n",
    "2. Compute the cosine similarity between the user profile and each tf-idf vector, and store it into array `sims`. Tips: Use `linear_kernel` from scikit-learn to take the inner product, since all vectors are normalized. Also, flatten the output at the end.\n",
    "3. Identify the indices in `sims` that have the largest similarities. Tips: `a[::-1]` returns the reverse of list `a`. You may want to use the `numpy.argsort` method.\n",
    "4. Retrieve the item_ids from `self.i_id_to_item_id` that correspond to the indices found.\n",
    "5. Include in the recommendation list only items from `from_item_ids`, and exclude those in `item_ids_rated_by_user_id`.\n",
    "6. Return only the topN. Recommended items should be sorted from most to least similar to user profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "09591377fe5f0fa3585409300e1308d5",
     "grade": false,
     "grade_id": "recommend-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "revert": "def recommend(self, user_id, from_item_ids=None, topN=20):\n    \"\"\"\n    This function takes a user ID and an array of items (if given) from which the topN items should be recommended.\n    Recommendations are made based on cosine similarty between user profil and tf idf-vector.\n    \n    :return: topN recommended items as list of item IDs of length topN\n    :rtype: list\n    \"\"\"\n    \n    item_ids_rated_by_user_id = self.ratings.loc[ self.ratings['user'] == user_id ]['item'].tolist()\n\n    if from_item_ids is None:\n        from_item_ids = self.item_ids\n\n    # YOUR CODE HERE\n    raise NotImplementedError()\n\n    return recommendations\n    "
   },
   "outputs": [],
   "source": [
    "def recommend(self, user_id, from_item_ids=None, topN=20):\n",
    "    \"\"\"\n",
    "    This function takes a user ID and an array of items (if given) from which the topN items should be recommended.\n",
    "    Recommendations are made based on cosine similarty between user profil and tf idf-vector.\n",
    "    \n",
    "    :return: topN recommended items as list of item IDs of length topN\n",
    "    :rtype: list\n",
    "    \"\"\"\n",
    "    \n",
    "    item_ids_rated_by_user_id = self.ratings.loc[ self.ratings['user'] == user_id ]['item'].tolist()\n",
    "\n",
    "    if from_item_ids is None:\n",
    "        from_item_ids = self.item_ids\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    #arr = get_user_profile(self, user_id, ratings)\n",
    "    arr = self.user_profiles[user_id]\n",
    "    tfidf = self.tfidf \n",
    "    sims = linear_kernel(arr, tfidf)\n",
    "    sims = sims.flatten()\n",
    "    sims = np.argsort(sims)\n",
    "    sims = sims[::-1]\n",
    "    newlist = []\n",
    "    for i in sims:\n",
    "        newlist.append(self.i_id_to_item_id[i])\n",
    "\n",
    "    filteredlist = []\n",
    "    for n in newlist:\n",
    "        if n in from_item_ids and n not in item_ids_rated_by_user_id:\n",
    "            filteredlist.append(n)\n",
    "\n",
    "    recommendations = filteredlist[:topN]\n",
    "    return recommendations\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a659747336796088fb5201ce973172d7",
     "grade": false,
     "grade_id": "cell-558e0390c36814ad",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Add the function to the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0288b8af16dadd631fbfda8acea86c1c",
     "grade": false,
     "grade_id": "cell-8b3a99aa4544ec2a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "Recommender_CB.recommend = recommend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e9c6ec47b16ab21b3642828d9ea4acc9",
     "grade": false,
     "grade_id": "cell-af8810ded6dd8b81",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Test the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "revert": "recs = cbr.recommend(1)\nprint(recs)\nprint(cbr.recommend(2))\nprint(cbr.recommend(3))\nprint(cbr.recommend(4))\nprint(cbr.recommend(5))\nprint(cbr.recommend(6))"
   },
   "outputs": [],
   "source": [
    "recs = cbr.recommend(1)\n",
    "print(recs)\n",
    "print(cbr.recommend(2))\n",
    "print(cbr.recommend(3))\n",
    "print(cbr.recommend(4))\n",
    "print(cbr.recommend(5))\n",
    "print(cbr.recommend(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1971dfa9c1a1d630cf7c6a79d73b7bce",
     "grade": false,
     "grade_id": "cell-a81e9b5540f1cf13",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**EXPECTED OUTPUT:**\n",
    "\n",
    "```\n",
    "[22, 9, 65, 40, 20, 61, 6, 86, 94, 88, 44, 13, 3, 18, 92, 15, 85, 81, 78, 90]\n",
    "[31, 5, 71, 58, 49, 57, 54, 64, 90, 94, 72, 88, 84, 76, 78, 97, 2, 37, 44, 52]\n",
    "[40, 18, 2, 65, 60, 92, 61, 30, 84, 21, 17, 81, 90, 78, 10, 87, 58, 47, 77, 42]\n",
    "[13, 92, 24, 46, 76, 87, 86, 85, 84, 83, 82, 81, 80, 79, 78, 77, 75, 89, 74, 73]\n",
    "[31, 72, 64, 55, 54, 76, 14, 45, 23, 75, 67, 44, 66, 46, 78, 39, 43, 84, 34, 73]\n",
    "[31, 5, 64, 57, 60, 46, 45, 92, 18, 39, 38, 82, 84, 50, 73, 34, 99, 23, 48, 76]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6b81a4b3bebb85afc434bbf31e5558fb",
     "grade": true,
     "grade_id": "recommend-test",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "57d04d4debc49add24460fce50b42de1",
     "grade": false,
     "grade_id": "cell-0c1301ed0fdbbf36",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Show the movie titles of the recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b4bee320509398ade7b66822a9a114a1",
     "grade": false,
     "grade_id": "cell-33be581eb2920314",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "display(cbr.get_item_titles(recs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "revert": "# feel free to use this field for additional tests"
   },
   "outputs": [],
   "source": [
    "# feel free to use this field for additional tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "revert": "# feel free to use this field for additional tests"
   },
   "outputs": [],
   "source": [
    "# feel free to use this field for additional tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "revert": "# feel free to use this field for additional tests"
   },
   "outputs": [],
   "source": [
    "# feel free to use this field for additional tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "revert": "# feel free to use this field for additional tests"
   },
   "outputs": [],
   "source": [
    "# feel free to use this field for additional tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "revert": "# feel free to use this field for additional tests"
   },
   "outputs": [],
   "source": [
    "# feel free to use this field for additional tests"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
