{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c954e11-ba7b-4177-ab7f-654cdfd60e05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query file Article ID: ['FALTER_20150204B39E03880F']\n",
      "Theme: ['Feuilleton']\n",
      "Title: ['Like mich am Arsch!']\n",
      "Subtitle: ['Under the glaring-crazy surface, Deichkind is one of the smartest pop bands in Germany. The new album proves this once more']\n",
      "Authors: [\"['Begegnung: Gerhard Stöger']\"]\n",
      "Chars: [8905]\n",
      "\n",
      "Article ID: ['FALTER_2015091699890360D5']\n",
      "Cosine_similarity to query file: 0.10467868115743142\n",
      "Theme: ['Feuilleton']\n",
      "Title: ['Spaß, Schweiß und Zigarettenrauch']\n",
      "Subtitle: ['For almost a year, Wanda has been considered the hottest shit in German-speaking pop. The waltz wanted to know how horny that feels and accompanied the band, who released their second album at the beginning of October, on Tourbus']\n",
      "Authors: [\"['Embedded Journalist: Klaus Nüchtern']\"]\n",
      "Chars: [16453]\n",
      "\n",
      "Article ID: ['FALTER_20150819C082867E45']\n",
      "Cosine_similarity to query file: 0.07023585843732422\n",
      "Theme: ['Feuilleton']\n",
      "Title: ['Der Bub, der zwei Mädchen ist']\n",
      "Subtitle: ['The German-Swiss duo Boy also puts on harmonious pop with its second album']\n",
      "Authors: [\"['PORTRÄT: GERHARD STÖGER']\"]\n",
      "Chars: [5468]\n",
      "\n",
      "Article ID: ['FALTER_201504222A7DBA9613']\n",
      "Cosine_similarity to query file: 0.13986603274695575\n",
      "Theme: ['Feuilleton']\n",
      "Title: ['\"Liebe ist auch etwas Gefährliches\"']\n",
      "Subtitle: ['The German band Tocotronic combines rebellion and romance on their new album. Singer Dirk von Lowtzow on his youth room, German rap, solidarity and the Beach Boys']\n",
      "Authors: [\"['Interview: Gerhard Stöger']\"]\n",
      "Chars: [13031]\n",
      "\n",
      "Article ID: ['FALTER_20150211E922F295D6']\n",
      "Cosine_similarity to query file: 0.12533933221117038\n",
      "Theme: ['Feuilleton']\n",
      "Title: ['\"Wir sind die neuen Helden\"']\n",
      "Subtitle: ['Picture book have made the local pop sexy. Now their new album will be released. Singer Maurice Ernst talks to the butterfly about Falco, Exzess and the Festivalmafia']\n",
      "Authors: [\"['INTERVIEW: GERHARD STÖGER']\"]\n",
      "Chars: [15818]\n",
      "\n",
      "Article ID: ['FALTER_201504085C39421185']\n",
      "Cosine_similarity to query file: 0.10999399596548391\n",
      "Theme: ['Feuilleton']\n",
      "Title: ['Die Band mit der AMORE']\n",
      "Subtitle: [\"A year ago they played in small cellars, now Wanda get their first golden record and they fill the gasometer. What's behind the Viennese pop miracle?\"]\n",
      "Authors: [\"['Porträt: Gerhard Stöger']\"]\n",
      "Chars: [15119]\n",
      "\n",
      "Article ID: ['FALTER_201508190A33F56644']\n",
      "Cosine_similarity to query file: 0.04349427045014247\n",
      "Theme: ['Lexikon']\n",
      "Title: ['Visionär und Retter des Hip-Hop']\n",
      "Subtitle: ['Master rapper Kendrick Lamar comes to the Frequency Festival in St. Pölten']\n",
      "Authors: [\"['PORTRÄT: SEBASTIAN FASTHUBER']\"]\n",
      "Chars: [4834]\n",
      "\n",
      "Article ID: ['FALTER_201510146A37887BDE']\n",
      "Cosine_similarity to query file: 0.12042783457396541\n",
      "Theme: ['Feuilleton']\n",
      "Title: ['\"Ich würde die Band heute nie mehr NAKED LUNCH nennen\"']\n",
      "Subtitle: ['Birthday without nostalgia: Naked Lunch become 25, publish a work show and reflect their moving career between Kellerloch and Popstar Glam']\n",
      "Authors: [\"['GESPRÄCH: GERHARD STÖGER']\"]\n",
      "Chars: [12138]\n",
      "\n",
      "Article ID: ['FALTER_20150610A250FFB3FD']\n",
      "Cosine_similarity to query file: 0.07802492191198183\n",
      "Theme: ['Lexikon']\n",
      "Title: ['\"Noch ist alles im grünen Bereich\"']\n",
      "Subtitle: ['On the sold-out Arena-Open-Air: a conversation with picture book singer Maurice Ernst']\n",
      "Authors: [\"['Interview: Gerhard Stöger']\"]\n",
      "Chars: [4495]\n",
      "\n",
      "Article ID: ['FALTER_20150204460A2D5372']\n",
      "Cosine_similarity to query file: 0.08365080754564669\n",
      "Theme: ['Lexikon']\n",
      "Title: ['Haftbefehl auf \"Lass die Affen aus\\'m Zoo\"-Tour']\n",
      "Subtitle: [nan]\n",
      "Authors: [\"['GS']\"]\n",
      "Chars: [2157]\n",
      "\n",
      "Article ID: ['FALTER_20150930B3A3F18669']\n",
      "Cosine_similarity to query file: 0.11055073634109262\n",
      "Theme: ['Feuilleton']\n",
      "Title: ['\"Ich liebe Miley Cyrus\"']\n",
      "Subtitle: ['The Viennese musician Clara Luzia releases a new album. A conversation about Christine Lavant, H. -C. Strache and Wanda, about feminism, good people and nudity']\n",
      "Authors: [\"['Interview: Gerhard Stöger']\"]\n",
      "Chars: [15504]\n",
      "\n",
      "Article ID: ['FALTER_201501287BEEE6754D']\n",
      "Cosine_similarity to query file: 0.08477304872761937\n",
      "Theme: ['Falter & Meinung']\n",
      "Title: ['Remmidemmi']\n",
      "Subtitle: [nan]\n",
      "Authors: [\"['GERHARD STÖGER CHRISTOPHER WURMDOBLER']\"]\n",
      "Chars: [2986]\n",
      "\n",
      "Article ID: ['FALTER_201501210440F94321']\n",
      "Cosine_similarity to query file: 0.06170100803753341\n",
      "Theme: ['Medien']\n",
      "Title: ['Radio FM40']\n",
      "Subtitle: ['FM4 is the young radio station of ORF and is increasingly being heard by adults. A critical tribute to the 20th birthday. ']\n",
      "Authors: [\"['AUF EMPFANG: SEBASTIAN FASTHUBER']\"]\n",
      "Chars: [8165]\n",
      "\n",
      "Article ID: ['FALTER_20150715F62B384AE7']\n",
      "Cosine_similarity to query file: 0.0941770928714953\n",
      "Theme: ['Feuilleton']\n",
      "Title: ['OLLAS LEIWAUND']\n",
      "Subtitle: [\"Before the Popfest Vienna, the local pop miracle is on everyone's lips. But how Viennese are Wanda, Bilderbuch and Co? And what exactly is this miracle?\"]\n",
      "Authors: [\"['EINSCHÄTZUNG: GERHARD STÖGER']\"]\n",
      "Chars: [15875]\n",
      "\n",
      "Article ID: ['FALTER_201505202EA32F1CA3']\n",
      "Cosine_similarity to query file: 0.07481184259869432\n",
      "Theme: ['Politik']\n",
      "Title: ['DER WICHTIG-MACHER']\n",
      "Subtitle: ['AIDS charity organizer Gery Keszler had to make his HIV infection public. The declining willingness of the Life Ball Society to donate forced him to do so. ']\n",
      "Authors: [\"['PORTRÄT: CHRISTOPHER WURMDOBLER']\"]\n",
      "Chars: [11693]\n",
      "\n",
      "Article ID: ['FALTER_20150204D87E5E2247']\n",
      "Cosine_similarity to query file: 0.06056716593325573\n",
      "Theme: ['Falter & Meinung']\n",
      "Title: ['Die Köpfe dieser Ausgabe']\n",
      "Subtitle: ['Authors in the folder']\n",
      "Authors: ['[]']\n",
      "Chars: [711]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "from zipfile import ZipFile\n",
    "import itertools\n",
    "\n",
    "\n",
    "directory = os.getcwd()\n",
    "file_name = \"2015_labeled_dataset.zip\"\n",
    "csv_file_directory = directory + \"/articles_2015_translated.csv\"\n",
    "all_articles = (pd.read_csv(csv_file_directory, usecols = [\"article_id\"])).values.tolist()\n",
    "all_paragraphs = (pd.read_csv(csv_file_directory, usecols = [\"paragraphs\"])).values.tolist()\n",
    "all_themes = (pd.read_csv(csv_file_directory, usecols = [\"ressort\"])).values.tolist()\n",
    "all_titles = (pd.read_csv(csv_file_directory, usecols = [\"title\"])).values.tolist()\n",
    "all_characters = (pd.read_csv(csv_file_directory, usecols = [\"characters\"])).values.tolist()\n",
    "all_authors = (pd.read_csv(csv_file_directory, usecols = [\"authors\"])).values.tolist()\n",
    "all_subtitles = (pd.read_csv(csv_file_directory, usecols = [\"subtitle_en\"])).values.tolist()\n",
    "\n",
    "\n",
    "with ZipFile(file_name, 'r') as zip:\n",
    "    all_files = zip.namelist()\n",
    "\n",
    "query_file = \"2015_labeled_dataset/FALTER_20150204B39E03880F.csv\"\n",
    "rec_files = pd.read_csv(query_file, header = None)\n",
    "rec_files = rec_files.values.tolist()\n",
    "query_file = query_file.split(\"/\")[1]\n",
    "query_file = query_file.replace(\".csv\", \"\")\n",
    "\n",
    "\n",
    "def get_ids(query_file, rec_files):\n",
    "    article_ids = {}\n",
    "    for this_file in rec_files:\n",
    "        this_file = str(this_file)\n",
    "        this_file = this_file.replace(\"\\\\\", \"\"); this_file = this_file.replace(\"['\", \"\"); this_file = this_file.replace(\"']\", \"\")\n",
    "        this_file = this_file.split(\"t\")\n",
    "        for i in range(len(all_articles)):\n",
    "            this_article = \"\".join(all_articles[i])\n",
    "            if this_article == query_file:\n",
    "    #            query_unique, tot_words_query = unique_words(\"\".join(paragraphs[i]))\n",
    "                query_index = i\n",
    "            elif this_article == this_file[0]:\n",
    "                article_ids[i] = this_file[0]\n",
    "                break\n",
    "    return article_ids, query_index\n",
    "\n",
    "\n",
    "def remove_special_chars(paragraph):\n",
    "    whitelist = set('abcdefghijklmnopqrstuvwxyz ABCDEFGHIJKLMNOPQRSTUVWXYZ äüö ÄÜÖ ß')\n",
    "    paragraph = ''.join(filter(whitelist.__contains__, paragraph))\n",
    "    paragraph = re.sub(\" +\",\" \", paragraph)\n",
    "    paragraph = paragraph.split(\" \")\n",
    "    return paragraph\n",
    "\n",
    "\n",
    "def count_words(paragraph, unique_words_for_all_texts):\n",
    "    word_freq = {}\n",
    "    for word in paragraph:\n",
    "        word = word.lower()\n",
    "        if word not in word_freq.keys():\n",
    "            word_freq[word] = 1\n",
    "            if word not in unique_words_for_all_texts.keys():\n",
    "                unique_words_for_all_texts[word] = 1\n",
    "            else:\n",
    "                val = unique_words_for_all_texts[word]\n",
    "                val+=1\n",
    "                unique_words_for_all_texts[word] = val\n",
    "        else:\n",
    "            val = word_freq[word]\n",
    "            val+=1\n",
    "            word_freq[word] = val\n",
    "    return word_freq, unique_words_for_all_texts\n",
    "\n",
    "\n",
    "def normalize_tf(unique_words):\n",
    "    for word, count in unique_words.items():\n",
    "        tf = math.log10(1+count)\n",
    "        unique_words[word] = tf\n",
    "    return unique_words\n",
    "\n",
    "\n",
    "def compute_tf(ID, unique_words_for_all_texts):\n",
    "    paragraph = remove_special_chars(\"\".join(all_paragraphs[ID]))\n",
    "    unique_words, unique_words_for_all_texts = count_words(paragraph, unique_words_for_all_texts)\n",
    "    tf_dictionary = normalize_tf(unique_words)\n",
    "    return tf_dictionary, unique_words_for_all_texts\n",
    "\n",
    "\n",
    "def multiple_tfs(article_ids):\n",
    "    all_tf_dicts = {}\n",
    "    unique_words_for_all_texts = {}\n",
    "    for ID, FalterNR in article_ids.items():\n",
    "        tf_dictionary,unique_words_for_all_texts = compute_tf(ID, unique_words_for_all_texts)\n",
    "        all_tf_dicts[ID] = tf_dictionary\n",
    "    return all_tf_dicts, unique_words_for_all_texts\n",
    "\n",
    "\n",
    "def compute_idf(unique_words_for_all_texts):\n",
    "    idf_dict = {}\n",
    "    for word, count in unique_words_for_all_texts.items():\n",
    "        idf = math.log10(len(article_ids.values())/count)\n",
    "        idf_dict[word] = idf\n",
    "    return idf_dict\n",
    "\n",
    "\n",
    "def compute_tfidf(tf_dict, idf_dict):\n",
    "    tfidf_dict = {}\n",
    "    for word, tf_score in tf_dict.items():\n",
    "        try:\n",
    "            tfidf_score = tf_score*idf_dict[word]\n",
    "            tfidf_dict[word] = tfidf_score\n",
    "        except KeyError:\n",
    "            continue\n",
    "    return tfidf_dict\n",
    "\n",
    "\n",
    "def multiple_tfidfs(all_tf_dicts, idf_dict):\n",
    "    all_tfidf_dict = {}\n",
    "    for ID, tf_dict in all_tf_dicts.items():\n",
    "        tfidf_dict = compute_tfidf(tf_dict, idf_dict)\n",
    "        all_tfidf_dict[ID] = tfidf_dict\n",
    "    return all_tfidf_dict\n",
    "\n",
    "\n",
    "def compute_cos_sim(query_tfidf, tfidf_dict):\n",
    "    cosine_sim_dict = {}\n",
    "    for ID, current_tfidf_dict in tfidf_dict.items():\n",
    "        dot_product = 0\n",
    "        query_len = 0\n",
    "        for query_word, query_tfidf_score in query_tfidf.items():\n",
    "            query_len+=(query_tfidf_score)**2\n",
    "            doc_len = 0\n",
    "            for word, tfidf_score in current_tfidf_dict.items():\n",
    "                doc_len+=(tfidf_score)**2\n",
    "                if query_word == word:\n",
    "                    dot_product+=(query_tfidf_score * tfidf_score)\n",
    "        cosine_sim_dict[ID] = (dot_product / (math.sqrt(query_len) * math.sqrt(doc_len)))\n",
    "    return cosine_sim_dict\n",
    "\n",
    "\n",
    "def biggest_tfidf_score(tfidf_dict):\n",
    "    print_list = []\n",
    "    sorted_dict= dict(sorted(tfidf_dict.items(), key=lambda item: item[1]))\n",
    "    sorted_dict = dict(reversed(list(sorted_dict.items())))\n",
    "    biggest_words = list(sorted_dict.keys())\n",
    "    for word in biggest_words:\n",
    "        if word in query_tf.keys():\n",
    "            print_list.append(word)\n",
    "    return print_list\n",
    "\n",
    "\n",
    "article_ids, queryfile_index = get_ids(query_file, rec_files)\n",
    "all_tf_dicts, unique_words_for_all_texts = multiple_tfs(article_ids)\n",
    "idf_dict = compute_idf(unique_words_for_all_texts)\n",
    "tfidf_dict = multiple_tfidfs(all_tf_dicts, idf_dict)\n",
    "query_tf, x = compute_tf(queryfile_index, {})\n",
    "query_tfidf = compute_tfidf(query_tf, idf_dict)\n",
    "cosine_sim = compute_cos_sim(query_tfidf, tfidf_dict)\n",
    "\n",
    "\n",
    "print(f\"Query file Article ID: {all_articles[queryfile_index]}\")\n",
    "print(f\"Theme: {all_themes[queryfile_index]}\")\n",
    "print(f\"Title: {all_titles[queryfile_index]}\")\n",
    "print(f\"Subtitle: {all_subtitles[queryfile_index]}\")\n",
    "print(f\"Authors: {all_authors[queryfile_index]}\")\n",
    "print(f\"Chars: {all_characters[queryfile_index]}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "for ID, value in cosine_sim.items():\n",
    "    print(f\"Article ID: {all_articles[ID]}\")\n",
    "    print(f\"Cosine_similarity to query file: {value}\")\n",
    "    print(f\"Theme: {all_themes[ID]}\")\n",
    "    print(f\"Title: {all_titles[ID]}\")\n",
    "    print(f\"Subtitle: {all_subtitles[ID]}\")\n",
    "    print(f\"Authors: {all_authors[ID]}\")\n",
    "    print(f\"Chars: {all_characters[ID]}\\n\")\n",
    "    #print(f\"highest scoring words: {biggest_tfidf_score(tfidf_dict[ID])}\\n\")\n",
    "\n",
    "\n",
    "#Prøve å sjekke for symmetri (se om anbefalte dokumenter anbefaler query fil tilbake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616645db-1dad-4924-96c6-ae1cf5d966b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d725237f-e3ad-442f-be19-7d8393ad4d91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
