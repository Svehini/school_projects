# school_projects
Some projects from assignments, mostly from Vienna

SAKODAS_MODEL.py:
The file sakoda's model, is a program that shows the segragation of blue vs red, (or X vs O) in a neighborhood. This program will ask for some inputs of number of rows and number of columns in the neighborhood. It will also ask about the number of total neighbors living there, and the distribution for blue and red neighbors. It will also ask for the percentage of similar neighbors, which if the percentage given is 75%, atleast 75% of all neighbors (not including empty spaces) must be the same kind as themselves. It will print out the mapping of the neighborhood for each iteration.

ASSIGNMENT1.py:
This assignment was from a subject at Technische Universität in Vienna called Recommender systems. Here we made a basic recommender system using the panda's Dataframe. We recieved a halfdone code, which we were to finish, so my code is the code underneath the "#YOUR CODE HERE" prompt.

ASSIGNMENT2.ipynb, ASSIGNMENT3.ipynb & ASSIGNMENT4.ipynb:
These were all assignments from recommender systems aswell, but these three assignments were more connected. Her we got some halfdone code, which we were to finish. This code wont work without the csv files, but since they´re over 25MB, I was not able to add them to GitHub. 
  In these three assignments I made some different types of recommender systems, which used different types of recommening, such as Content Based recommending, User-Used recommending and Item-Item recommendation. My part of the code is the code under the line "#YOUR CODE HERE"

BAG_OF_WORDS.ipynb & VISUALIZATION_PHASE2.ipynb:
These files are from an assignment from recommender systems again, but this was a bigger group-assignment, where I made the files "bag_of_words.ipynb", and "visualizations_phase2.ipynb". The Bag of words file, is my own version of a bag of words model, which makes a vecxtorspace from different texts to see which files have the most similar TFIDF-vector score (basically which files are more similar in terms of words). The visalization file visualized different assets from  big csv-file full of news articles. In this csv-files there were a big list of articles which had corresponding assets such as "Article_id", "title", "paragraaphs", "author", etc etc. Here I used some of the different assets to visualize which files were a better match and recommendation for other files, and did some calculations, such as in the Bag Of Words model.
